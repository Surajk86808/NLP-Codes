# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1igo2fdCttCfuRAhq0W3rnU4BhrxfeAVJ
"""

import numpy as np
import pandas as pd

emotion_df = pd.read_csv('/content/text.csv')

emotion_df.head()

violence_df = pd.read_csv('/content/Train.csv')

violence_df.head()

hate_df = pd.read_csv('/content/labeled_data.csv')

hate_df.head()

# Check if 'Unnamed: 0' exists in emotion_df before dropping
if 'Unnamed: 0' in emotion_df.columns:
    emotion_df.drop(columns=['Unnamed: 0'], inplace=True)

# Check if 'Tweet_ID' exists in violence_df before dropping
if 'Tweet_ID' in violence_df.columns:
    violence_df.drop(columns=['Tweet_ID'], inplace=True)

# Correctly drop columns from hate_df, checking for existence
columns_to_drop_hate = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither']
existing_columns_hate = [col for col in columns_to_drop_hate if col in hate_df.columns]
hate_df.drop(columns=existing_columns_hate, inplace=True)

emotion_df.head()

violence_df.head()

hate_df.head()

hate_df = hate_df[['tweet','class']]

hate_df.head()

emotion_df.columns , violence_df.columns , hate_df.columns

violence_df.rename(columns={'tweet':'text','type':'label'},inplace=True)

hate_df.rename(columns={'tweet':'text','class':'label'},inplace=True)

# null
print(emotion_df.isnull().sum())
print('*'*20)
print(hate_df.isnull().sum())
print('*'*20)
print(violence_df.isnull().sum())
print('*'*20)

emotion_df.shape,violence_df.shape,hate_df.shape

# Taking 12k from row from each as they dont have same number of rows
emotion_df['label'].value_counts()

e_df = pd.DataFrame()
for i in range(6):
  subset = emotion_df[emotion_df['label']==i].sample(n=2000,random_state=42)
  e_df = pd.concat([e_df,subset])

e_df.shape

emotion_df = e_df.copy()

emotion_df['label'].value_counts()

violence_df['label'].value_counts()

sexual_violence = violence_df[violence_df['label']=='sexual_violence'].sample(n=4998,random_state=42)
violence_df = violence_df[violence_df['label'] != 'sexual_violence']

violence_df.shape

violence_df = pd.concat([violence_df,sexual_violence],axis=0)
violence_df.shape

hate_df['label'].value_counts()

offensive_speech = hate_df[hate_df['label'] == 1].sample(n= 6407 , random_state=42)
hate_df = hate_df[hate_df['label'] != 1]

hate_df.shape

hate_df = pd.concat([offensive_speech, hate_df],axis = 0)

hate_df.shape

emotion_df.shape,hate_df.shape,violence_df.shape

emotion_df.head(3)

hate_df.head(3)

violence_df.head(3)

# resetting the index values as they are very different to each other
emotion_df.reset_index(drop = True ,inplace = True)
violence_df.reset_index(drop = True ,inplace = True)
hate_df.reset_index(drop = True ,inplace = True)

emotion_df.head(3)

violence_df.head(3)

hate_df.head(3)

# Label encoding
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

label_encoder = LabelEncoder()
violence_df['label'] = label_encoder.fit_transform(violence_df['label'])

violence_df.head()

violence_df['label'].unique()

# Stop words removal
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

# loading the stopwords
stop_words = set(stopwords.words('english'))

stop_words

# [53] #stopwords removal function

def remove_stopwords(text):
    all_words = nltk.word_tokenize(text)
    filtered_words = [word for word in all_words if word.lower() not in stop_words]
    return ' '.join(filtered_words)

emotion_df['text'] = emotion_df['text'].apply(remove_stopwords)
violence_df['text'] = violence_df['text'].apply(remove_stopwords)
hate_df['text'] = violence_df['text'].apply(remove_stopwords)

# Toeknization and Padding
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer()
tokenizer.fit_on_texts(pd.concat([emotion_df['text'],violence_df['text'],hate_df['text']]))

emotion_sequences = tokenizer.texts_to_sequences(emotion_df['text'])
violence_sequences = tokenizer.texts_to_sequences(violence_df['text'])
hate_sequences = tokenizer.texts_to_sequences(hate_df['text'])

emotion_df['text'].iloc[2]

emotion_sequences[2:3]

max_length = 50
emotion_padded = pad_sequences(emotion_sequences, maxlen=max_length, padding='post')
emotion_padded.shape

violence_padded = pad_sequences(violence_sequences, maxlen=max_length, padding='post')
violence_padded.shape

hate_padded = pad_sequences(hate_sequences, maxlen=max_length, padding='post')
hate_padded.shape

emotion_padded[2:3]

# converting to numpy
import numpy as np
emotion_labels = np.array(emotion_df['label'])
violence_labels = np.array(violence_df['label'])
hate_labels = np.array(hate_df['label'])

# Model definition
emotion_input = emotion_padded
violence_input = violence_padded
hate_input = hate_padded

# defining multiple input layer for each task
from tensorflow import keras
emotion_input_layer = keras.layers.Input(shape = (max_length,),name='emotion_input')
violence_input_layer = keras.layers.Input(shape = (max_length,),name='violence_input')
hate_input_layer = keras.layers.Input(shape = (max_length,),name='hate_input')

# Used a shared embedding layer
embedding_layer = keras.layers.Embedding(input_dim = len(tokenizer.word_index)+ 1 , output_dim = 128)

# Applying embedding layer to each input
emotion_embedding = embedding_layer(emotion_input_layer)
violence_embedding = embedding_layer(violence_input_layer)
hate_embedding = embedding_layer(hate_input_layer)

# Shared LSTM layer
shared_lstm = keras.layers.LSTM(64, return_sequences=True)

emotion_lstm = shared_lstm(emotion_embedding)
violence_lstm = shared_lstm(violence_embedding)
hate_lstm =  shared_lstm(hate_embedding)

# shared global average pooling layer and dropout layer
shared_pooling = keras.layers.GlobalAveragePooling1D()
shared_dropout = keras.layers.Dropout(0.5)

emotion_features = shared_dropout(shared_pooling(emotion_lstm))
violence_features = shared_dropout(shared_pooling(violence_lstm))
hate_features = shared_dropout(shared_pooling(hate_lstm))

print(len(emotion_df['label'].unique()))
print(len(violence_df['label'].unique()))
print(len(hate_df['label'].unique()))

# output layers
emotion_output = keras.layers.Dense(6,activation='softmax',name='emotion_output')(emotion_features)
violence_output = keras.layers.Dense(5,activation='softmax',name='violence_output')(violence_features)
hate_output = keras.layers.Dense(3,activation='softmax',name='hate_output')(hate_features)

model = keras.models.Model(
    inputs = [emotion_input_layer,violence_input_layer,hate_input_layer],
    outputs = [emotion_output,violence_output,hate_output]
)

#Compile the model with multiple inputs and outputs


model.compile(
    optimizer = 'adam',
    loss = {
        'emotion_output':'sparse_categorical_crossentropy',
        'violence_output':'sparse_categorical_crossentropy',
        'hate_output':'sparse_categorical_crossentropy'
    },
    metrics = {
        'emotion_output': 'accuracy',
        'violence_output': 'accuracy',
        'hate_output': 'accuracy'
    }
)

model.summary()

model.fit(
  x = {
    'emotion_input':emotion_input,
    'violence_input':violence_input,
    'hate_input': hate_input
  },
  y = {
     'emotion_output': emotion_labels,
     'violence_output' : violence_labels,
     'hate_output' : hate_labels
  },
  epochs = 10,
  batch_size = 4
)

# prediction and evaluation
prediction = model.predict({
    'emotion_input':emotion_input,
    'violence_input':violence_input,
    'hate_input':hate_input
})

emotion_pred = np.argmax(prediction[0],axis = 1)
violence_pred = np.argmax(prediction[0],axis = 1)
hate_pred = np.argmax(prediction[0],axis = 1)

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
# %matplotlib inline

violence_df['label'].unique()

def plot_cm(true,pred,title,labels):
  cf = confusion_matrix(true,pred)
  df_cm = pd.DataFrame(cf,index=labels,columns=labels)
  plt.figure(figsize=(10,10))
  sns.heatmap(df_cm,annot=True,cmap=plt.cm.Blues,fmt='g')
  plt.title(title)
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()


emotion_label_text = ['sadness','joy','love','anger','fear','surprise']
violence_label_text = ['sexual_violence','physical_violence','emotional_violence','Harmful_traditional_practice','economic_violence']
hate_label_text = ['offensive_speech','Neither','Hate Speech']

plot_cm(emotion_labels,emotion_pred,'confusion matrix for emotion',emotion_label_text)
plot_cm(violence_labels,violence_pred,'confusion matrix for violence',violence_label_text)
plot_cm(hate_labels,hate_pred,'confusion matrix for hate',hate_label_text)

def classify_text(input_text):
    #preprocess the input text
    input_text_cleaned = remove_stopwords(input_text)
    input_sequence = tokenizer.texts_to_sequences([input_text_cleaned])
    input_padded = pad_sequences(input_sequence, maxlen = max_length, padding = 'post')

    #prediction
    prediction = model.predict({'emotion_input' : emotion_padded,
                                'violence_input': violence_padded,
                                'hate_input': hate_padded})

    emotion_pred = np.argmax(prediction[0], axis = 1)
    violence_pred = np.argmax(prediction[1], axis = 1)
    hate_pred = np.argmax(prediction[2], axis = 1)

    #determine major label
    major_labels = ['Emotion', 'Violence', 'Hate']
    major_label_index = np.argmax([np.max(predictions[0]), np.max(predictions[1]), np.max(predictions[2])])
    major_label = major_labels[major_label_index]

    #determing sub - labels
    emotion_labels_text = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']
    violence_labels_text = ['sexual_violence', 'physical_violence', 'emotional_violence', 'Harmful_traditional_practice',]
    hate_labels_text = ['offensive speech', 'Neither', 'Hate Speech']

    if major_label == 'Emotion':
        sub_label = emotion_labels_text[emotion_pred]
    elif major_label == 'Violence':
        sub_label = violence_labels_text[violence_pred]
    else:
        sub_label = hate_labels_text[hate_pred]

    return major_label, sub_label

import ipywidgets as widgets
from IPython.display import display

#define a text widget and a placeholder
input_text_widget = widgets.Text(
    description = 'Input text : ',
    placeholder = 'Enter you text'
)

#define classify button
button = widgets.Button(description = 'classify')

#define an output area to display result
output = widgets.Output()

#function to handle event
def on_button_click(b):
    with output:
        output.clear_output() #clear the previous output
        input_text = input_text_widget.value
        major_label, sub_label = classify_text(input_text)
        print(f'Major Label : {major_label}')
        print(f'Sub Label : {sub_label}')

#attach the button at bottom
button.on_click(on_button_click)

display(input_text_widget, button, output)